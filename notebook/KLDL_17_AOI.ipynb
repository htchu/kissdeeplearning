{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KvrRl029pPB"
      },
      "source": [
        "<img src=\"https://i.ibb.co/qjt4Ymb/2022-09-19-004719.png\" alt=\"2022-09-19-004719\" border=\"0\">\n",
        "\n",
        "# Topic 17: AOI-Automated Optical Inspection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhFS0k6edj4s"
      },
      "source": [
        "# AIdea AOI Project\n",
        "* This tutorial uses the AOI dataset of the AIdea platform.\n",
        "* Introduce how to write deep learning programs to classify defects in automatic optical inspection.\n",
        "* This notebook program can be executed in the cloud using Google Colab or Jupyter on a personal computer.\n",
        "\n",
        "AIdea AOI Project\n",
        "https://aidea-web.tw/topic/285ef3be-44eb-43dd-85cc-f0388bf85ea4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkguTuu0doDW"
      },
      "source": [
        "# (A) AIdea dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gdown"
      ],
      "metadata": {
        "id": "4mbLEZq1qacQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f82204-ef0d-48fa-89bf-2917e97b4d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMzNhOKcFJTV"
      },
      "source": [
        "## Step 1: Load the AIdea AOI dataset from google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install --upgrade gdown\n",
        "gdown https://drive.google.com/uc?id=1tovCO2gsjesjJ8OsfHgahyt-buY34dk0"
      ],
      "metadata": {
        "id": "g5mvntWHqhAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd81f897-8c66-4b90-8325-8f9bfa53ff2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tovCO2gsjesjJ8OsfHgahyt-buY34dk0\n",
            "To: /content/aoi-dataset.zip\n",
            "\r  0%|          | 0.00/1.76G [00:00<?, ?B/s]\r  0%|          | 4.72M/1.76G [00:00<02:29, 11.7MB/s]\r  1%|          | 17.3M/1.76G [00:00<01:30, 19.2MB/s]\r  1%|▏         | 25.7M/1.76G [00:01<01:01, 28.4MB/s]\r  2%|▏         | 42.5M/1.76G [00:01<00:32, 52.3MB/s]\r  4%|▎         | 64.5M/1.76G [00:01<00:19, 85.4MB/s]\r  5%|▌         | 89.1M/1.76G [00:01<00:13, 120MB/s] \r  6%|▋         | 114M/1.76G [00:01<00:10, 150MB/s] \r  8%|▊         | 135M/1.76G [00:01<00:09, 165MB/s]\r  9%|▉         | 159M/1.76G [00:01<00:08, 185MB/s]\r 10%|█         | 180M/1.76G [00:02<00:14, 113MB/s]\r 11%|█▏        | 202M/1.76G [00:02<00:19, 80.8MB/s]\r 13%|█▎        | 222M/1.76G [00:02<00:15, 98.1MB/s]\r 14%|█▎        | 238M/1.76G [00:02<00:20, 73.6MB/s]\r 14%|█▍        | 252M/1.76G [00:03<00:22, 67.9MB/s]\r 15%|█▌        | 266M/1.76G [00:03<00:19, 77.4MB/s]\r 16%|█▌        | 277M/1.76G [00:03<00:22, 67.0MB/s]\r 17%|█▋        | 294M/1.76G [00:03<00:22, 65.9MB/s]\r 17%|█▋        | 303M/1.76G [00:03<00:23, 62.2MB/s]\r 18%|█▊        | 311M/1.76G [00:04<00:41, 34.8MB/s]\r 19%|█▉        | 336M/1.76G [00:04<00:29, 48.4MB/s]\r 20%|█▉        | 344M/1.76G [00:05<00:27, 51.5MB/s]\r 21%|██        | 361M/1.76G [00:05<00:22, 60.8MB/s]\r 21%|██        | 370M/1.76G [00:05<00:23, 58.1MB/s]\r 21%|██▏       | 378M/1.76G [00:05<00:26, 52.1MB/s]\r 22%|██▏       | 395M/1.76G [00:05<00:24, 56.3MB/s]\r 24%|██▍       | 424M/1.76G [00:05<00:14, 93.2MB/s]\r 25%|██▍       | 437M/1.76G [00:06<00:16, 81.4MB/s]\r 26%|██▌       | 455M/1.76G [00:06<00:13, 97.2MB/s]\r 27%|██▋       | 468M/1.76G [00:06<00:13, 96.7MB/s]\r 27%|██▋       | 480M/1.76G [00:06<00:16, 78.5MB/s]\r 28%|██▊       | 491M/1.76G [00:06<00:15, 84.3MB/s]\r 28%|██▊       | 501M/1.76G [00:06<00:16, 78.3MB/s]\r 29%|██▉       | 511M/1.76G [00:07<00:16, 77.8MB/s]\r 30%|███       | 529M/1.76G [00:07<00:16, 74.1MB/s]\r 31%|███       | 537M/1.76G [00:07<00:22, 54.9MB/s]\r 32%|███▏      | 563M/1.76G [00:07<00:15, 76.4MB/s]\r 32%|███▏      | 571M/1.76G [00:07<00:16, 70.0MB/s]\r 33%|███▎      | 588M/1.76G [00:08<00:15, 74.8MB/s]\r 34%|███▍      | 596M/1.76G [00:08<00:15, 74.4MB/s]\r 34%|███▍      | 605M/1.76G [00:08<00:20, 55.2MB/s]\r 35%|███▌      | 621M/1.76G [00:08<00:20, 56.6MB/s]\r 36%|███▋      | 638M/1.76G [00:09<00:18, 61.4MB/s]\r 37%|███▋      | 655M/1.76G [00:09<00:16, 66.4MB/s]\r 38%|███▊      | 672M/1.76G [00:09<00:19, 57.0MB/s]\r 39%|███▉      | 694M/1.76G [00:09<00:13, 79.8MB/s]\r 40%|████      | 706M/1.76G [00:10<00:16, 65.2MB/s]\r 42%|████▏     | 730M/1.76G [00:10<00:12, 79.9MB/s]\r 42%|████▏     | 740M/1.76G [00:10<00:13, 76.4MB/s]\r 44%|████▍     | 771M/1.76G [00:10<00:08, 116MB/s] \r 45%|████▌     | 798M/1.76G [00:10<00:06, 145MB/s]\r 46%|████▋     | 817M/1.76G [00:11<00:12, 75.2MB/s]\r 47%|████▋     | 836M/1.76G [00:11<00:10, 90.2MB/s]\r 48%|████▊     | 851M/1.76G [00:11<00:14, 63.8MB/s]\r 50%|████▉     | 873M/1.76G [00:11<00:10, 81.0MB/s]\r 50%|█████     | 887M/1.76G [00:12<00:13, 63.7MB/s]\r 52%|█████▏    | 915M/1.76G [00:12<00:12, 66.0MB/s]\r 53%|█████▎    | 936M/1.76G [00:12<00:09, 83.0MB/s]\r 54%|█████▍    | 949M/1.76G [00:12<00:10, 77.7MB/s]\r 55%|█████▍    | 965M/1.76G [00:13<00:09, 85.2MB/s]\r 56%|█████▌    | 982M/1.76G [00:13<00:09, 81.3MB/s]\r 56%|█████▋    | 992M/1.76G [00:13<00:09, 83.1MB/s]\r 57%|█████▋    | 1.00G/1.76G [00:13<00:08, 88.1MB/s]\r 58%|█████▊    | 1.02G/1.76G [00:13<00:09, 78.2MB/s]\r 59%|█████▊    | 1.03G/1.76G [00:13<00:08, 90.2MB/s]\r 59%|█████▉    | 1.04G/1.76G [00:13<00:07, 94.4MB/s]\r 60%|█████▉    | 1.05G/1.76G [00:14<00:12, 57.9MB/s]\r 61%|██████    | 1.07G/1.76G [00:14<00:11, 58.7MB/s]\r 62%|██████▏   | 1.08G/1.76G [00:14<00:09, 71.0MB/s]\r 62%|██████▏   | 1.10G/1.76G [00:14<00:09, 72.5MB/s]\r 63%|██████▎   | 1.12G/1.76G [00:15<00:08, 80.1MB/s]\r 64%|██████▍   | 1.13G/1.76G [00:15<00:14, 41.9MB/s]\r 66%|██████▌   | 1.15G/1.76G [00:16<00:10, 58.9MB/s]\r 66%|██████▋   | 1.17G/1.76G [00:16<00:10, 56.3MB/s]\r 67%|██████▋   | 1.18G/1.76G [00:16<00:08, 69.7MB/s]\r 68%|██████▊   | 1.20G/1.76G [00:16<00:07, 71.0MB/s]\r 69%|██████▉   | 1.21G/1.76G [00:16<00:07, 76.1MB/s]\r 70%|██████▉   | 1.23G/1.76G [00:16<00:07, 75.1MB/s]\r 70%|███████   | 1.23G/1.76G [00:17<00:07, 70.8MB/s]\r 71%|███████   | 1.25G/1.76G [00:17<00:08, 61.5MB/s]\r 73%|███████▎  | 1.28G/1.76G [00:17<00:05, 95.2MB/s]\r 73%|███████▎  | 1.29G/1.76G [00:17<00:06, 70.3MB/s]\r 74%|███████▍  | 1.30G/1.76G [00:18<00:06, 70.4MB/s]\r 75%|███████▌  | 1.33G/1.76G [00:18<00:04, 89.5MB/s]\r 76%|███████▋  | 1.34G/1.76G [00:18<00:05, 76.1MB/s]\r 77%|███████▋  | 1.35G/1.76G [00:18<00:04, 82.2MB/s]\r 78%|███████▊  | 1.37G/1.76G [00:18<00:04, 79.3MB/s]\r 79%|███████▊  | 1.38G/1.76G [00:18<00:03, 95.4MB/s]\r 80%|████████  | 1.41G/1.76G [00:19<00:04, 79.5MB/s]\r 81%|████████  | 1.43G/1.76G [00:19<00:03, 89.5MB/s]\r 82%|████████▏ | 1.44G/1.76G [00:19<00:05, 59.9MB/s]\r 83%|████████▎ | 1.47G/1.76G [00:20<00:03, 84.7MB/s]\r 84%|████████▍ | 1.48G/1.76G [00:20<00:03, 70.0MB/s]\r 85%|████████▍ | 1.49G/1.76G [00:20<00:04, 59.1MB/s]\r 86%|████████▌ | 1.51G/1.76G [00:20<00:03, 78.2MB/s]\r 87%|████████▋ | 1.53G/1.76G [00:20<00:03, 67.4MB/s]\r 87%|████████▋ | 1.54G/1.76G [00:21<00:04, 54.3MB/s]\r 89%|████████▊ | 1.56G/1.76G [00:21<00:02, 71.9MB/s]\r 89%|████████▉ | 1.57G/1.76G [00:21<00:02, 71.0MB/s]\r 91%|█████████ | 1.59G/1.76G [00:21<00:02, 80.9MB/s]\r 92%|█████████▏| 1.61G/1.76G [00:22<00:01, 87.8MB/s]\r 93%|█████████▎| 1.63G/1.76G [00:22<00:01, 83.7MB/s]\r 93%|█████████▎| 1.64G/1.76G [00:22<00:01, 86.2MB/s]\r 94%|█████████▍| 1.66G/1.76G [00:22<00:01, 78.7MB/s]\r 95%|█████████▌| 1.67G/1.76G [00:22<00:00, 86.4MB/s]\r 96%|█████████▋| 1.70G/1.76G [00:23<00:00, 91.1MB/s]\r 97%|█████████▋| 1.71G/1.76G [00:23<00:00, 102MB/s] \r 98%|█████████▊| 1.72G/1.76G [00:23<00:00, 72.1MB/s]\r 99%|█████████▊| 1.74G/1.76G [00:23<00:00, 71.6MB/s]\r100%|█████████▉| 1.75G/1.76G [00:23<00:00, 80.5MB/s]\r100%|██████████| 1.76G/1.76G [00:23<00:00, 73.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "unzip aoi-dataset.zip\n",
        "rm aoi-dataset.zip"
      ],
      "metadata": {
        "id": "A7IQ_8FNqt9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR_KADlQk7Gs"
      },
      "source": [
        "## Step 2: read the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaFX5Cqgicw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7b866e-978c-4f96-97e3-959d9ba1e3e1"
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "print(df_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2528, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dwc7F7dioM7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f30032ca-9518-4b70-a45a-03e6b5c4b85a"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                ID  Label\n",
              "0  train_00000.png      0\n",
              "1  train_00001.png      1\n",
              "2  train_00002.png      1\n",
              "3  train_00003.png      5\n",
              "4  train_00004.png      5"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4199fbbc-2bea-4d09-9718-e24716eedb4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_00000.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_00001.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_00002.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_00003.png</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_00004.png</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4199fbbc-2bea-4d09-9718-e24716eedb4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4199fbbc-2bea-4d09-9718-e24716eedb4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4199fbbc-2bea-4d09-9718-e24716eedb4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHjI9HpmRfac"
      },
      "source": [
        "## Step 3: Build the lists of training images and labels from the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LizhcbfXis75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae51f26e-c1fe-4a66-f366-7c7bfae010df"
      },
      "source": [
        "#limit the amount of training images for the class process\n",
        "#train_num = 480\n",
        "train_num = df_train.shape[0]\n",
        "if train_num >= df_train.shape[0]:\n",
        "  train_num = df_train.shape[0]\n",
        "train_files = df_train.iloc[:train_num,0].values\n",
        "train_labels = df_train.iloc[:train_num,1].values\n",
        "print(train_labels[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 1 5 5 5 3 0 3 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uImM5L4DlG4X"
      },
      "source": [
        "## Step 4: read images of the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2GH166li2f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8bd06a6-d45b-4bd5-8ec8-ed23d0c2f003"
      },
      "source": [
        "train_path =\"train_images/\"\n",
        "train_images = []\n",
        "from tensorflow.keras.preprocessing import image\n",
        "for file in train_files:\n",
        "    img = image.load_img(train_path+file, color_mode=\"rgb\", target_size = (299, 299))\n",
        "    train_images.append(img)\n",
        "    if len(train_images)%100 == 0:\n",
        "      print('.', end='')\n",
        "print(len(train_images))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".........................2528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acQAGGlik5Gz"
      },
      "source": [
        "## Step 5: show AOI images of the classes: \n",
        "0 (normal), 1 (void), 2 (horizontal  defect) 3 (vertical defect), 4 (edge defect), 5 (particle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqB5T0_yk21r"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xBuhRnLlmTM"
      },
      "source": [
        "import random\n",
        "curclass = 0\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        curclass += 1\n",
        "        curclass %= 6\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA2AWBT09Klk"
      },
      "source": [
        "# Class 0-normal\n",
        "import random\n",
        "curclass = 0\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvcrqsuM9Zof"
      },
      "source": [
        "# Class 1-void\n",
        "import random\n",
        "curclass = 1\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttimxvzo9mgs"
      },
      "source": [
        "# Class 2-horizontal defect\n",
        "import random\n",
        "curclass = 2\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xRwCCZt9vyS"
      },
      "source": [
        "# Class 3-vertical defect\n",
        "import random\n",
        "curclass = 3\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avZBx0Lq9ymv"
      },
      "source": [
        "# Class 4-edge defect\n",
        "import random\n",
        "curclass = 4\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrLNwULy90IJ"
      },
      "source": [
        "# Class 5-particle\n",
        "import random\n",
        "curclass = 5\n",
        "fig,ax=plt.subplots(2, 3)\n",
        "fig.set_size_inches(10,10)\n",
        "for i in range(2):\n",
        "    for j in range (3):\n",
        "        sel=random.randint(0,train_num)\n",
        "        while train_labels[sel]!=curclass:\n",
        "          sel +=1\n",
        "          if sel == train_num -1:\n",
        "            sel = 0\n",
        "        #sel=random.randint(0,train_num)\n",
        "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
        "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMxY9IGumAew"
      },
      "source": [
        "## Step 6: Show statistics of training images in the 6 classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGZkuGS3mTCO"
      },
      "source": [
        "import numpy as np\n",
        "labels, counts = np.unique(train_labels, return_counts=True)\n",
        "print(labels, counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTX_Anx0mWzQ"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 5))\n",
        "plt.bar(labels, counts, width=0.7, align='center')\n",
        "plt.title(\"Label Distribution\")\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(labels)\n",
        "plt.ylim(0, 680)\n",
        "\n",
        "for a, b in zip(labels, counts):\n",
        "    plt.text(a, b, '%d' % b, ha='center', va='bottom', fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD4ZBffHX71W"
      },
      "source": [
        "# (B) TensorFlow 2.0 Keras applications with ImageNet models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c20jGAYlcW5j"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQtcWITNcMHK"
      },
      "source": [
        "## Step 7: Keras Applications Models\n",
        "<img src=\"https://miro.medium.com/max/1571/1*XB4SlSGxGKFQbIBoil0aDg.png\" alt=\"Pre-train models\" width=\"500\">\n",
        "\n",
        "Pre-train models of tf.Keras includes Xception、VGG16、VGG19、ResNet50、InceptionV3、InceptionResNetV2、MobileNet、DenseNet、NASNet、MobileNetV2\n",
        "<img src=\"https://miro.medium.com/max/1280/0*L8egayRvFZOAmvqc.png\" alt=\"Pre-train models\" width=\"500\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxLyEiuFEIgI"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "model = InceptionV3(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpyO_On4Egdx"
      },
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "model = Xception(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su_yDmG6EkkX"
      },
      "source": [
        "from tensorflow.keras.applications import NASNetLarge\n",
        "from tensorflow.keras.applications.nasnet import preprocess_input\n",
        "model = NASNetLarge(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh36dHu0EtH_"
      },
      "source": [
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
        "model = InceptionResNetV2(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ8_jQYQExo3"
      },
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "model = MobileNetV2(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WZxmhSPE4D8"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
        "model = ResNet50V2(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCVO6g04GFMi"
      },
      "source": [
        "## Step 8: Keras Applications preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZzsTx4cHrze"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
        "x = image.img_to_array(train_images[0])\n",
        "img_array = preprocess_input(x, mode = 'tf' )\n",
        "print(img_array[0 , 0 , 0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaW40jTcIh0g"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
        "x = image.img_to_array(train_images[0])\n",
        "img_array = preprocess_input(x, mode = 'torch' )\n",
        "print(img_array[0 , 0 , 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkwlHXQunZ02"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
        "x = image.img_to_array(train_images[0])\n",
        "img_array = preprocess_input(x, mode = 'caffe' )\n",
        "print(img_array[0 , 0 , 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDkl3H-woXKA"
      },
      "source": [
        "## Step 9: Tranfer learning\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1000/1*frBNwuPg0kUsWFqfBlvxLg.png\" alt=\"Pre-train models\" width=\"500\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y-15yJXn_LM"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Activation\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSObvzWmofw_"
      },
      "source": [
        "#the InceptionV3 model \n",
        "num_classes = 6\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "base_model = InceptionV3(include_top = False, input_shape=(299,299,3), weights='imagenet', classes=num_classes)\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv9FohfRfmRs"
      },
      "source": [
        "base_model.trainable = False\n",
        "last_layer = base_model.output\n",
        "last_layer=Flatten()(last_layer)\n",
        "last_layer=Dropout(0.3)(last_layer)\n",
        "out = Dense(num_classes, activation='softmax', name='softmax')(last_layer)\n",
        "custom_model = Model(base_model.input, out)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}